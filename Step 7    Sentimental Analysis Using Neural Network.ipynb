{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569aca5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination_link</th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9376</td>\n",
       "      <td>Thank you for help making my honeymoon a memor...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9376</td>\n",
       "      <td>Our guide really made the tour great. The dest...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9376</td>\n",
       "      <td>I really appreciate everything that Travel Tal...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9376</td>\n",
       "      <td>Overall it was such a surreal and fun experien...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Destination_link                                             Review  \\\n",
       "0              9376  Thank you for help making my honeymoon a memor...   \n",
       "1              9376  Our guide really made the tour great. The dest...   \n",
       "2              9376  I really appreciate everything that Travel Tal...   \n",
       "3              9376  Overall it was such a surreal and fun experien...   \n",
       "\n",
       "   Sentiment Score  \n",
       "0                5  \n",
       "1                5  \n",
       "2                5  \n",
       "3                4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Combine Review Data set.csv\")[['Destination_link','Review','Sentiment Score']]\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f226c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7912, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4cf386f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Destination_link    0\n",
       "Review              0\n",
       "Sentiment Score     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e3d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['Review']\n",
    "y = df['Sentiment Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39605cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7912,)\n",
      "(7912,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459b7a6",
   "metadata": {},
   "source": [
    "## Now we will apply some preprocessing on the x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1caa5525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Thank you for help making my honeymoon a memor...\n",
       "1       Our guide really made the tour great. The dest...\n",
       "2       I really appreciate everything that Travel Tal...\n",
       "3       Overall it was such a surreal and fun experien...\n",
       "4       I really enjoyed me tour it was excellent. I m...\n",
       "                              ...                        \n",
       "7907    We did a Blossom Tour with Hunza Explorer and ...\n",
       "7908    We were a bit anxious about Pakistan before th...\n",
       "7909    Well designed itinerary to see blossom in Hunz...\n",
       "7910    We did a Blossom Tour with Hunza Explorer and ...\n",
       "7911    We were a bit anxious about Pakistan before th...\n",
       "Name: Review, Length: 7912, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d38dee",
   "metadata": {},
   "source": [
    "## importing libraries for text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5f9d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa734d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\seher\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e7ac766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cad8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating obj of the porter stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2c3ae4",
   "metadata": {},
   "source": [
    "# Applying preprocessing on data\n",
    "\n",
    "- Removing unwanted Characters\n",
    "- eliminate stop words\n",
    "- lower case\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e52f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for showing the progress bcz it's takes time \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a86c69a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7912/7912 [02:04<00:00, 63.61it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in tqdm(range(0, len(x))):\n",
    "    review = re.sub('[^a-zA-Z]', \" \", x[i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [ stemmer.stem(words) for words in review if not words in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "956ca5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one best tour ever join thank travel talk great servic amaz time spent tour tour well organ tour leader deve help inform hotel stay star show'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8bdc5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\seher\\anaconda3\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (14.0.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.21.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (21.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.42.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.19.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (61.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (4.1.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (22.11.23)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.33.0)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.30.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.3)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\seher\\anaconda3\\lib\\site-packages (from packaging->tensorflow-gpu) (3.0.4)\n",
      "Installing collected packages: requests\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.18.4\n",
      "    Uninstalling requests-2.18.4:\n",
      "      Successfully uninstalled requests-2.18.4\n",
      "Successfully installed requests-2.30.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aab82e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8098ac",
   "metadata": {},
   "source": [
    "## Creating Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "412baf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d9f2653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41ec71f",
   "metadata": {},
   "source": [
    "## Getting indexes after applying the one hot ecoding using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3e3ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_rep = [ one_hot(word, vocab_size) for word in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e665d3",
   "metadata": {},
   "source": [
    "## Finding the highest len of the review in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96e8a7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_rep[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "825fb959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_rep[3400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2eccd3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_rep[5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a6eb1602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "max_list = max(one_hot_rep, key=len)\n",
    "\n",
    "# Print the result\n",
    "print(len(max_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c0c3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7911/7911 [00:00<00:00, 357424.42it/s]\n"
     ]
    }
   ],
   "source": [
    "lenght = 46\n",
    "for i in tqdm(range(1, len(corpus))):\n",
    "    if lenght < len(one_hot_rep[i]):\n",
    "        lenght = len(one_hot_rep[i])\n",
    "        print(lenght, \" and the index is:\" , i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2b8e7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thank help make honeymoon memor experi well done travel talk'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0a27ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58baf2a",
   "metadata": {},
   "source": [
    "### let's find the mean here for the sentence len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6912eb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7912/7912 [00:00<00:00, 506391.18it/s]\n"
     ]
    }
   ],
   "source": [
    "sum_len = 0\n",
    "for i in tqdm(range(0, len(corpus))):\n",
    "    sum_len = sum_len + len(one_hot_rep[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19d2770b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.120070778564205"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_len / len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece79d7",
   "metadata": {},
   "source": [
    "## So here we considered the max len 130 and the the review above that len will get discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "858294fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 130"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80eb5a",
   "metadata": {},
   "source": [
    "### Applying pedding to keep the size of the input same that's why we above find the len of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61acba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_data = pad_sequences(one_hot_rep, padding = 'post', maxlen = length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0e0679b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([458739, 400507, 288708, 170460, 525994, 637232, 162668, 199762,\n",
       "       237668, 738393, 640301, 257049, 400507, 227871, 162668, 880515,\n",
       "       288708, 705461, 393822, 369239, 233141, 137496, 617824, 466170,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_data[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef9e35",
   "metadata": {},
   "source": [
    "### Embedding Layer\n",
    "It performs embedding operations in input layer. It is used to convert positive into dense vectors of fixed size. Its main application is in text analysis. \n",
    "\n",
    "### As we get tense vocab, now we need to convert it into the vectors.\n",
    "\n",
    "### for this, we will be taking each word and than representing it with the number of features (let say we pass the len 8, than each word is represented by 8 different values which are actually the features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6b20f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer_features = 170"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf49f3",
   "metadata": {},
   "source": [
    "## Using Bidirectional LSTM here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "080ba2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding( input_dim = vocab_size,output_dim = embedding_layer_features, input_length = length))\n",
    "model.add(Bidirectional(LSTM(200)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer = \"adam\", metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9a467ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7912, (7912,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padding_data), y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fc1be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = padding_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e993b",
   "metadata": {},
   "source": [
    "## Splitting of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37bdf5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cdf265",
   "metadata": {},
   "source": [
    "## Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4dd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e4d848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516/516 [==============================] - 90s 170ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "436ec3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "b=np.where(y_pred > 0.6, 1,0) ##AUC ROC Curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb1f0d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7202, 1006],\n",
       "       [1677, 6615]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da94c2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84      8208\n",
      "           1       0.87      0.80      0.83      8292\n",
      "\n",
      "    accuracy                           0.84     16500\n",
      "   macro avg       0.84      0.84      0.84     16500\n",
      "weighted avg       0.84      0.84      0.84     16500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62b386fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8373939393939394"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9db61787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27615</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21964</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33321</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40225</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28203</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment_positive\n",
       "33553                   1\n",
       "9427                    1\n",
       "199                     0\n",
       "12447                   1\n",
       "39489                   0\n",
       "...                   ...\n",
       "27615                   1\n",
       "21964                   1\n",
       "33321                   1\n",
       "40225                   1\n",
       "28203                   0\n",
       "\n",
       "[16500 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8183fec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
